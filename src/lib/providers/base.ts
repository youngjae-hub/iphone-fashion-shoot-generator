// ============================================
// Base Provider Interface - ìœ ì—°í•œ Provider êµì²´ë¥¼ ìœ„í•œ ì¶”ìƒí™”
// ============================================

import { PoseType, GeneratedImage, GenerationSettings, VTONCategory } from '@/types';

// ì´ë¯¸ì§€ ìƒì„± Provider ì¸í„°í˜ì´ìŠ¤
export interface IImageGenerationProvider {
  name: string;
  generateModelImage(options: ModelGenerationOptions): Promise<string>;
  generateBackground(options: BackgroundOptions): Promise<string>;
  isAvailable(): Promise<boolean>;
}

// Virtual Try-On Provider ì¸í„°í˜ì´ìŠ¤
export interface ITryOnProvider {
  name: string;
  tryOn(options: TryOnOptions): Promise<string>;
  isAvailable(): Promise<boolean>;
}

// ì˜µì…˜ íƒ€ì…ë“¤
export interface ModelGenerationOptions {
  pose: PoseType;
  style: string;
  seed?: number;
  negativePrompt?: string;
  garmentImage?: string; // base64 ì´ë¯¸ì§€ - ì´ ì˜·ì„ ì…íŒ ëª¨ë¸ ìƒì„±
  styleReferenceImages?: string[]; // base64 ì´ë¯¸ì§€ ë°°ì—´ - ì´ ìŠ¤íƒ€ì¼ë“¤ì„ ì°¸ì¡° (ìµœëŒ€ 10ì¥)
  backgroundSpotImages?: string[]; // base64 ì´ë¯¸ì§€ ë°°ì—´ - ì´ ë°°ê²½/ì¥ì†Œë¥¼ ì°¸ì¡°í•˜ì—¬ ìƒì„±
  customPrompt?: string; // ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (í”„ë¡¬í”„íŠ¸ ì—ë””í„°ì—ì„œ ì„¤ì •)
}

export interface BackgroundOptions {
  style: string;
  prompt?: string;
  referenceImage?: string;
}

export interface TryOnOptions {
  garmentImage: string; // base64
  modelImage?: string; // base64, optional - ì—†ìœ¼ë©´ ëª¨ë¸ë„ ìƒì„±
  pose: PoseType;
  category?: VTONCategory; // ì˜ë¥˜ ì¹´í…Œê³ ë¦¬: upper_body, lower_body, dresses
  seed?: number; // ê° ì»·ë§ˆë‹¤ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œê°’
}

// Provider Registry - ëŸ°íƒ€ì„ì— Provider êµì²´ ê°€ëŠ¥
export class ProviderRegistry {
  private static imageGenerationProviders: Map<string, IImageGenerationProvider> = new Map();
  private static tryOnProviders: Map<string, ITryOnProvider> = new Map();

  static registerImageGeneration(name: string, provider: IImageGenerationProvider) {
    this.imageGenerationProviders.set(name, provider);
  }

  static registerTryOn(name: string, provider: ITryOnProvider) {
    this.tryOnProviders.set(name, provider);
  }

  static getImageGeneration(name: string): IImageGenerationProvider | undefined {
    return this.imageGenerationProviders.get(name);
  }

  static getTryOn(name: string): ITryOnProvider | undefined {
    return this.tryOnProviders.get(name);
  }

  static listImageGenerationProviders(): string[] {
    return Array.from(this.imageGenerationProviders.keys());
  }

  static listTryOnProviders(): string[] {
    return Array.from(this.tryOnProviders.keys());
  }
}

// ì•„ì´í° ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„± ìœ í‹¸ë¦¬í‹° (VTON í˜¸í™˜ - ì „ì²´ ì–¼êµ´ í•„ìš”)
// ë ˆí¼ëŸ°ìŠ¤: ì‡¼í•‘ëª° ëª¨ë¸ì»· ìŠ¤íƒ€ì¼ (ìì—°ê´‘, ë¯¸ë‹ˆë©€ ë°°ê²½, ëª©ê¹Œì§€ í¬ë¡­)
export function generateIPhoneStylePrompt(pose: PoseType, additionalPrompt?: string): string {
  // âš ï¸ VTONì´ ì‹ ì²´ë¥¼ ê°ì§€í•˜ë ¤ë©´ ì „ì²´ ì–¼êµ´ì´ ë³´ì—¬ì•¼ í•¨ (ì–¼êµ´ í¬ë¡­ì€ VTON í›„ í›„ì²˜ë¦¬ë¡œ)
  const basePrompt = `
    iPhone photography style, natural window lighting,
    young Korean female model with long black wavy hair,
    full body shot with visible face,
    high-quality fashion lookbook, sharp details,
    natural skin texture, minimal cozy interior background,
    white walls, wooden floor, simple furniture,
    professional fashion e-commerce photography
  `.trim().replace(/\s+/g, ' ');

  // ë ˆí¼ëŸ°ìŠ¤ ëª¨ë¸ì»· ê¸°ë°˜ í¬ì¦ˆ í”„ë¡¬í”„íŠ¸
  const posePrompts: Record<PoseType, string> = {
    front: 'front view, standing straight, arms relaxed at sides, looking slightly off camera, natural stance',
    back: 'back view, showing garment back details, slight head turn, long hair visible',
    side: '3/4 angle view, body turned 45 degrees, elegant silhouette, one hand relaxed',
    sitting: 'sitting on white sofa or wooden chair, relaxed pose, legs together or crossed, natural lifestyle feel',
    styled: 'dynamic editorial pose, hand touching hair or near face, natural movement, lifestyle editorial feel',
    fullbody: 'full body shot from head to toe, standing pose, feet visible, generous framing with floor visible',
  };

  return `${basePrompt}, ${posePrompts[pose]}${additionalPrompt ? `, ${additionalPrompt}` : ''}`;
}

// ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ê¸°ë³¸ê°’ (VTON í˜¸í™˜ - ì–¼êµ´ ì œí•œ ì œê±°)
export const DEFAULT_NEGATIVE_PROMPT = `
  low quality, blurry, distorted, deformed, ugly,
  bad anatomy, bad proportions, extra limbs,
  watermark, signature, text, logo,
  oversaturated, artificial lighting
`.trim().replace(/\s+/g, ' ');

// â­ï¸ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤ë§ˆíŠ¸ í¬ë¡­ (Google Vision API ì‚¬ìš©)
/**
 * ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ì ì ˆí•œ ìœ„ì¹˜ì—ì„œ í¬ë¡­
 * - ìƒì˜/ì›í”¼ìŠ¤: í„± ì•„ë˜~ëª© ìœ„ì¹˜ì—ì„œ í¬ë¡­ (ëª©ì´ ë³´ì´ë„ë¡)
 * - í•˜ì˜: ê°€ìŠ´~ë°°ê¼½ ìœ„ì¹˜ì—ì„œ í¬ë¡­
 * @param imageInput - base64 ì´ë¯¸ì§€
 * @param category - ì˜ë¥˜ ì¹´í…Œê³ ë¦¬ (upper_body, lower_body, dresses)
 * @returns í¬ë¡­ëœ base64 ì´ë¯¸ì§€
 */
export async function smartFaceCrop(
  imageInput: string,
  category: 'upper_body' | 'lower_body' | 'dresses' = 'upper_body'
): Promise<string> {
  if (typeof window !== 'undefined') {
    // ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œëŠ” fallbackìœ¼ë¡œ ê³ ì • ë¹„ìœ¨ í¬ë¡­
    const fallbackPercent = category === 'lower_body' ? 35 : 15;
    return cropTopForPrivacy(imageInput, fallbackPercent);
  }

  const apiKey = process.env.GOOGLE_CLOUD_API_KEY;
  if (!apiKey) {
    console.warn('Google Cloud API key not found, falling back to fixed crop');
    const fallbackPercent = category === 'lower_body' ? 35 : 15;
    return cropTopForPrivacy(imageInput, fallbackPercent);
  }

  try {
    const sharp = require('sharp');

    // base64 ë°ì´í„° ì¶”ì¶œ
    const base64Data = imageInput.replace(/^data:image\/\w+;base64,/, '');
    const imageBuffer = Buffer.from(base64Data, 'base64');

    // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
    const metadata = await sharp(imageBuffer).metadata();
    const { width, height } = metadata;

    if (!width || !height) {
      const fallbackPercent = category === 'lower_body' ? 35 : 15;
      return cropTopForPrivacy(imageInput, fallbackPercent);
    }

    // Google Vision APIë¡œ ì–¼êµ´ ê°ì§€
    const visionResponse = await fetch(
      `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          requests: [{
            image: { content: base64Data },
            features: [{ type: 'FACE_DETECTION', maxResults: 1 }]
          }]
        })
      }
    );

    if (!visionResponse.ok) {
      console.warn('Vision API failed, falling back to fixed crop');
      const fallbackPercent = category === 'lower_body' ? 35 : 15;
      return cropTopForPrivacy(imageInput, fallbackPercent);
    }

    const visionData = await visionResponse.json();
    const faces = visionData.responses?.[0]?.faceAnnotations;

    if (!faces || faces.length === 0) {
      console.log('No face detected, using fixed crop');
      const fallbackPercent = category === 'lower_body' ? 35 : 15;
      return cropTopForPrivacy(imageInput, fallbackPercent);
    }

    // ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
    const face = faces[0];
    const landmarks = face.landmarks || [];

    // ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡­ ìœ„ì¹˜ ê²°ì •
    let cropY = 0;

    if (category === 'lower_body') {
      // í•˜ì˜: ê°€ìŠ´~ë°°ê¼½ ìœ„ì¹˜ì—ì„œ í¬ë¡­ (ì–¼êµ´ í•˜ë‹¨ì—ì„œ ë” ì•„ë˜ë¡œ)
      // ì–¼êµ´ í•˜ë‹¨ ì°¾ê¸°
      let faceBottom = 0;
      if (face.boundingPoly?.vertices) {
        faceBottom = Math.max(...face.boundingPoly.vertices.map((v: {y?: number}) => v.y || 0));
      }
      // ì–¼êµ´ í•˜ë‹¨ì—ì„œ ì´ë¯¸ì§€ ë†’ì´ì˜ 15% ë” ì•„ë˜ (ëŒ€ëµ ê°€ìŠ´~ë°°ê¼½)
      cropY = Math.floor(faceBottom + height * 0.15);
      console.log(`ğŸ‘– Lower body crop: at y=${cropY} (chest/belly level)`);
    } else {
      // ìƒì˜/ì›í”¼ìŠ¤: í„± ì•„ë˜~ëª© ìœ„ì¹˜ì—ì„œ í¬ë¡­
      // CHIN ë˜ëŠ” í„± ìœ„ì¹˜ ì°¾ê¸°
      let chinY = 0;
      for (const landmark of landmarks) {
        if (landmark.type === 'CHIN_GNATHION' || landmark.type === 'CHIN_LEFT_GONION' || landmark.type === 'CHIN_RIGHT_GONION') {
          chinY = Math.max(chinY, landmark.position.y);
        }
      }

      // í„± ëœë“œë§ˆí¬ê°€ ì—†ìœ¼ë©´ ì–¼êµ´ ì˜ì—­ì˜ í•˜ë‹¨ ì‚¬ìš©
      if (chinY === 0 && face.boundingPoly?.vertices) {
        const vertices = face.boundingPoly.vertices;
        chinY = Math.max(...vertices.map((v: {y?: number}) => v.y || 0));
      }

      if (chinY === 0) {
        return cropTopForPrivacy(imageInput, 15);
      }

      // í„± ì•„ë˜ ì•½ê°„ ì—¬ìœ ë¥¼ ë‘ê³  í¬ë¡­ (ëª©ì´ ë³´ì´ë„ë¡)
      cropY = Math.floor(chinY + 20); // í„± ì•„ë˜ 20px
      console.log(`ğŸ‘• Upper body crop: at y=${cropY} (below chin, showing neck)`);
    }

    const newHeight = height - cropY;

    // ì•ˆì „ ì²´í¬
    if (newHeight < height * 0.4) {
      console.log('Crop too aggressive, using fixed crop');
      const fallbackPercent = category === 'lower_body' ? 35 : 15;
      return cropTopForPrivacy(imageInput, fallbackPercent);
    }

    const croppedBuffer = await sharp(imageBuffer)
      .extract({
        left: 0,
        top: cropY,
        width: width,
        height: newHeight,
      })
      .toBuffer();

    console.log(`âœ… Smart crop completed for ${category}: cropped at y=${cropY}`);
    return `data:image/jpeg;base64,${croppedBuffer.toString('base64')}`;

  } catch (error) {
    console.error('Smart face crop failed:', error);
    const fallbackPercent = category === 'lower_body' ? 35 : 15;
    return cropTopForPrivacy(imageInput, fallbackPercent);
  }
}

// â­ï¸ Phase 1-1: ì–¼êµ´ í¬ë¡­ í›„ì²˜ë¦¬ - ìƒë‹¨ ì¼ì • ë¹„ìœ¨ ìë¥´ê¸° (fallbackìš©)
/**
 * ì´ë¯¸ì§€ ìƒë‹¨ì„ ì˜ë¼ì„œ ì–¼êµ´ ë…¸ì¶œ ë°©ì§€
 * @param imageInput - base64 ì´ë¯¸ì§€ ë˜ëŠ” URL
 * @param cropPercentage - ì˜ë¼ë‚¼ ìƒë‹¨ ë¹„ìœ¨ (ê¸°ë³¸ 20%)
 * @returns í¬ë¡­ëœ base64 ì´ë¯¸ì§€
 */
export async function cropTopForPrivacy(imageInput: string, cropPercentage: number = 20): Promise<string> {
  // Node.js í™˜ê²½ì—ì„œëŠ” sharp ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© í•„ìš”
  // ë¸Œë¼ìš°ì € í™˜ê²½ì—ì„œëŠ” Canvas API ì‚¬ìš©

  if (typeof window === 'undefined') {
    // ì„œë²„ í™˜ê²½ (Node.js) - sharp ì‚¬ìš©
    try {
      const sharp = require('sharp');

      let imageBuffer: Buffer;

      // URLì¸ ê²½ìš° fetchë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
      if (imageInput.startsWith('http://') || imageInput.startsWith('https://')) {
        console.log(`Fetching image from URL for cropping...`);
        try {
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000); // 30ì´ˆ íƒ€ì„ì•„ì›ƒ

          const response = await fetch(imageInput, { signal: controller.signal });
          clearTimeout(timeoutId);

          if (!response.ok) {
            throw new Error(`Failed to fetch image: ${response.status}`);
          }
          const arrayBuffer = await response.arrayBuffer();
          imageBuffer = Buffer.from(arrayBuffer);
        } catch (fetchError) {
          console.error('Failed to fetch image for cropping:', fetchError);
          return imageInput; // fetch ì‹¤íŒ¨ ì‹œ ì›ë³¸ URL ë°˜í™˜
        }
      } else {
        // base64ì¸ ê²½ìš°
        const base64Data = imageInput.replace(/^data:image\/\w+;base64,/, '');
        imageBuffer = Buffer.from(base64Data, 'base64');
      }

      // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
      const metadata = await sharp(imageBuffer).metadata();
      const { width, height } = metadata;

      if (!width || !height) {
        console.warn('Could not get image dimensions for cropping');
        return imageInput; // í¬ë¡­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
      }

      // ìƒë‹¨ í¬ë¡­ ê³„ì‚°
      const cropHeight = Math.floor(height * (cropPercentage / 100));
      const newHeight = height - cropHeight;

      // í¬ë¡­ ì‹¤í–‰
      const croppedBuffer = await sharp(imageBuffer)
        .extract({
          left: 0,
          top: cropHeight,
          width: width,
          height: newHeight,
        })
        .toBuffer();

      // base64ë¡œ ë‹¤ì‹œ ì¸ì½”ë”©
      console.log(`âœ… Image cropped successfully (${cropPercentage}% from top)`);
      return `data:image/jpeg;base64,${croppedBuffer.toString('base64')}`;

    } catch (error) {
      console.error('Image cropping failed:', error);
      return imageInput; // ì—ëŸ¬ ì‹œ ì›ë³¸ ë°˜í™˜
    }
  } else {
    // í´ë¼ì´ì–¸íŠ¸ í™˜ê²½ (ë¸Œë¼ìš°ì €) - Canvas API ì‚¬ìš©
    return new Promise((resolve) => {
      const img = new Image();
      img.onload = () => {
        const cropHeight = Math.floor(img.height * (cropPercentage / 100));
        const newHeight = img.height - cropHeight;

        const canvas = document.createElement('canvas');
        canvas.width = img.width;
        canvas.height = newHeight;

        const ctx = canvas.getContext('2d');
        if (!ctx) {
          resolve(imageInput);
          return;
        }

        // ì´ë¯¸ì§€ì˜ í•˜ë‹¨ ë¶€ë¶„ë§Œ ê·¸ë¦¬ê¸°
        ctx.drawImage(
          img,
          0, cropHeight, // ì†ŒìŠ¤ x, y
          img.width, newHeight, // ì†ŒìŠ¤ width, height
          0, 0, // ëŒ€ìƒ x, y
          img.width, newHeight // ëŒ€ìƒ width, height
        );

        resolve(canvas.toDataURL('image/jpeg', 0.95));
      };
      img.onerror = () => resolve(imageInput);
      img.src = imageInput;
    });
  }
}
